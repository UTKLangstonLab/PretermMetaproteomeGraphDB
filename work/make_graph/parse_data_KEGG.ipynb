{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KEGG data\n",
    "\n",
    "To get relevant data the following needs to be done:\n",
    "\n",
    "* Download compound, reaction and glycan objects `get_KEGG.R` \n",
    "* Download glycan-to-compound links using `wget http://rest.kegg.jp/link/cpd/gl -O \"gl-to-cpd-api.txt\"`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "from numpy import NaN as NaN\n",
    "import json\n",
    "from collections import defaultdict\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan/work/make_graph\r\n"
     ]
    }
   ],
   "source": [
    "!pwd -P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file paths in\n",
    "reactions_file_name       = '/home/jovyan/data/KEGG/KEGG_reactions.tsv'\n",
    "compounds_file_name       = '/home/jovyan/data/KEGG/KEGG_compounds.tsv'\n",
    "glycans_file_name         = '/home/jovyan/data/KEGG/KEGG_glycans.tsv'\n",
    "\n",
    "glycans_link_name         = '/home/jovyan/data/KEGG/gl-to-cpd-api.txt'\n",
    "compounds_brite_file_name = '/home/jovyan/data/KEGG/br08001.json'\n",
    "metacyc_file_name         = '/home/jovyan/data/KEGG/MetaCyc-Directions.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file paths out\n",
    "compound_entities_file      = '/home/jovyan/data/import/KEGG_compound_entities.tsv'\n",
    "reaction_entities_file      = '/home/jovyan/data/import/KEGG_reaction_entities.tsv'\n",
    "product_relationship_file   = '/home/jovyan/data/import/KEGG_relationship_PRODUCT.tsv'\n",
    "substrate_relationship_file = '/home/jovyan/data/import/KEGG_relationship_SUBSTRATE.tsv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nonspecific functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_to_string(x):\n",
    "    return \",\".join([str(i) for i in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reaction vertices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detag(x):\n",
    "    try:\n",
    "        soup = BeautifulSoup(x, \"html5lib\")\n",
    "        return list(set([x.strip('\\\"').upper() for x in soup.text.split(\" // \")]))\n",
    "    except Exception as e:\n",
    "        return [] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reactions = pd.read_csv(reactions_file_name, sep=\"\\t\", na_values=[\": NULL\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create synonym list\n",
    "df_reactions[\"SYNONYMS\"] = [df_reactions[\"NAME\"][i].split(\"; \") if df_reactions[\"NAME\"][i] is not NaN\n",
    "                        else [df_reactions[\"ENTRY\"][i]] \n",
    "                        for i in range(df_reactions.shape[0])]\n",
    "pd.isnull(df_reactions[\"SYNONYMS\"]).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace name\n",
    "df_reactions[\"NAME\"] = df_reactions[\"SYNONYMS\"].apply(lambda x: '\"%s\"'%x[0].replace('\"', \"'\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split enzymes\n",
    "df_reactions['ENZYME'] = df_reactions['ENZYME'].apply(lambda x: [\"%s\"%t for t in re.split(\"\\s+\", x)] \n",
    "                                                      if x is not NaN \n",
    "                                                      else [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the pathway ids \n",
    "df_reactions[\"PATHWAY\"] = [re.findall(r'rn[0-9]*', s) if s is not NaN \n",
    "                           else [] \n",
    "                           for s in df_reactions[\"PATHWAY\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# double quotes for the rest\n",
    "df_reactions['EQUATION'] = df_reactions['EQUATION'].apply(lambda x: '\"%s\"'%x)\n",
    "df_reactions['DEFINITION'] = df_reactions['DEFINITION'].apply(lambda x: '\"%s\"'%x.strip().replace('\"', \"'\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all lists to strings\n",
    "df_reactions[\"PATHWAY\"] = df_reactions[\"PATHWAY\"].apply(list_to_string)\n",
    "df_reactions[\"SYNONYMS\"] = df_reactions[\"SYNONYMS\"].apply(list_to_string)\n",
    "df_reactions[\"ENZYME\"] = df_reactions[\"ENZYME\"].apply(list_to_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reactions[\"DIRECTION_FROM_METACYC\"] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reactions = df_reactions[[\"ENTRY\", \"NAME\", \"SYNONYMS\", \"DEFINITION\", \"EQUATION\", \"ENZYME\", \"PATHWAY\", \"DIRECTION_FROM_METACYC\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reactions.columns = ['ID', \n",
    "                        'NAME',\n",
    "                        'SYNONYMS',\n",
    "                        'NAME_EQUATION', \n",
    "                        'EQUATION', \n",
    "                        'EC_NUMBERS', \n",
    "                        'PATHWAY', \n",
    "                        'DIRECTION_FROM_METACYC']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reactions.set_index(\"ID\", drop=False, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Direction from metacyc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "manually_checked_same = [\"R00026\", \"R00028\", \"R00034\", \"R00544\", \"R01501\", \"R00874\", \"R01101\", \n",
    "                         \"R01263\", \"R01369\", \"R01483\", \"R01484\", \"R01498\", \n",
    "                         \"R01645\", \n",
    "                         \"R02172\", \"R02183\", \"R02185\", \"R02341\", \"R02361\", \"R02465\", \"R02782\", \n",
    "                         \"R02816\", \"R02826\", \"R02963\", \"R02568\", \"R02602\", \"R02714\", \"R02716\", \n",
    "                         \"R02852\", \"R03020\", \"R03032\", \"R02287\", \"R03189\", \"R03204\", \"R09125\", \n",
    "                         \"R03246\", \"R03253\", \"R03256\", \"R03386\", \"R03519\", \"R03617\", \"R03677\", \n",
    "                         \"R06392\", \"R09398\", \"R09709\", \"R10209\", \"R10278\", \"R10469\", \"R10867\", \n",
    "                         \"R09967\", \"R09977\", \"R10029\", \"R10033\", \"R10051\", \"R09609\", \"R03789\", \n",
    "                         \"R03898\", \"R03959\", \"R04061\", \"R04081\", \"R04089\", \"R04104\", \"R04527\"]\n",
    "\n",
    "manually_checked_reversed = [\"R07790\", \"R02300\"]\n",
    "\n",
    "manually_checked_different = [\"R02718\", \"R10331\", \"R10667\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "metacyc_df = pd.read_csv(metacyc_file_name, sep=\"\\t\", \n",
    "                         usecols=[\"Reaction\", \"Reaction-Direction\", \"KEGG-RIGHT\", \"KEGG-LEFT\", \"KEGG\"])\n",
    "metacyc_df.dropna(subset=[\"KEGG\", \"Reaction-Direction\"], inplace=True)\n",
    "metacyc_df[\"KEGG\"] = metacyc_df[\"KEGG\"].apply(detag)\n",
    "\n",
    "b = pd.DataFrame(metacyc_df[\"KEGG\"].tolist(), index=metacyc_df.index).stack()\n",
    "b.name = \"KEGG-RXN\"\n",
    "b.index = b.index.droplevel(1)\n",
    "\n",
    "metacyc_df = metacyc_df.join(b)\n",
    "metacyc_df.set_index(\"KEGG-RXN\", inplace=True)\n",
    "metacyc_df.sort_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove different reactions\n",
    "metacyc_df.drop(manually_checked_different, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "metacyc_df.sort_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compounds mislinked in metacyc or tautomers/less/more specific\n",
    "D = {\"C00890\":\"C00404\", \"C00221\":\"C00031\", \"C00267\":\"C00031\", \n",
    "     \"C01342\":\"C00014\", \"C14823\":\"C04822\", \"C00962\":\"C00124\", \n",
    "     \"C02917\":\"C00583\", \"C01011\":\"C00904\", \"C00093\":\"C03189\", \n",
    "     \"D07349\":\"C00670\", \"C16073\":\"C02658\", \"C16072\":\"C00726\", \n",
    "     \"C02171\":\"C01117\", \"C00282\":\"C00030\", \"C04434\":\"C04324\", \n",
    "     \"C04548\":\"C01869\"}\n",
    "def replace(l):\n",
    "    return l + [D[c] for c in l if c in D]  \n",
    "\n",
    "metacyc_df[\"LEFT\"] = metacyc_df[\"KEGG-LEFT\"].apply(detag).apply(replace)\n",
    "metacyc_df[\"RIGHT\"] = metacyc_df[\"KEGG-RIGHT\"].apply(detag).apply(replace)\n",
    "\n",
    "del metacyc_df[\"KEGG-LEFT\"]\n",
    "del metacyc_df[\"KEGG-RIGHT\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_same(df):\n",
    "    return len(df.unique()) == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find duplicates by KEGG ID\n",
    "dups_idx = metacyc_df[metacyc_df.index.duplicated(False)][\"Reaction-Direction\"].groupby(level=0).aggregate(is_same)\n",
    "dups = metacyc_df.loc[dups_idx[dups_idx==True].index]\n",
    "\n",
    "# delete all rows that don't agree on direction\n",
    "metacyc_df.drop(dups_idx[dups_idx == False].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace aggregated rows that agree on direction\n",
    "dups = dups.groupby(level=0).aggregate({\"Reaction\":lambda x: ','.join(x), \n",
    "                                        \"KEGG\":sum,\n",
    "                                        \"Reaction-Direction\":lambda x:x.values[0], \n",
    "                                        \"RIGHT\":sum, \n",
    "                                        \"LEFT\":sum\n",
    "                                       })\n",
    "metacyc_df.loc[dups_idx[dups_idx==True].index] = dups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some reactions are defined by glycans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# glycan links\n",
    "f = lambda x:x.split(\":\")[1]\n",
    "df_gl_to_c = pd.read_csv(glycans_link_name, sep=\"\\t\", \n",
    "                         header=None, index_col=0, names=[\"gl\", \"compound\"], \n",
    "                         converters={0:f, 1:f})\n",
    "# remove glycans with multiple compound links (need to add seperately)\n",
    "df_gl_to_c = df_gl_to_c[~df_gl_to_c.index.duplicated(False)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def orient_reaction_same(substrate_list, product_list, direction):\n",
    "    if direction in (\"PHYSIOL-LEFT-TO-RIGHT\", \"IRREVERSIBLE-LEFT-TO-RIGHT\", \"LEFT-TO-RIGHT\"):\n",
    "        # no change to orientation\n",
    "        directed = True\n",
    "        substrate_list, product_list = substrate_list, product_list\n",
    "\n",
    "    elif direction in (\"PHYSIOL-RIGHT-TO-LEFT\", \"IRREVERSIBLE-RIGHT-TO-LEFT\", \"RIGHT-TO-LEFT\"):\n",
    "        # swop orientation\n",
    "        directed = True\n",
    "        substrate_list, product_list = product_list, substrate_list    \n",
    "    \n",
    "    elif direction == \"REVERSIBLE\":\n",
    "        directed = False\n",
    "\n",
    "    else:\n",
    "        print(direction, \"why am I here\")\n",
    "    \n",
    "    return substrate_list, product_list, directed\n",
    "\n",
    "def orient_reaction_reversed(substrate_list, product_list, direction):\n",
    "    # reaction is reversed from metacyc reaction definition\n",
    "    if direction in (\"PHYSIOL-LEFT-TO-RIGHT\", \"IRREVERSIBLE-LEFT-TO-RIGHT\", \"LEFT-TO-RIGHT\"):\n",
    "        # swop orientation\n",
    "        directed = True\n",
    "        substrate_list, product_list = product_list, substrate_list\n",
    "\n",
    "    elif direction in (\"PHYSIOL-RIGHT-TO-LEFT\", \"IRREVERSIBLE-RIGHT-TO-LEFT\", \"RIGHT-TO-LEFT\"):\n",
    "        # no change to orientation\n",
    "        directed = True\n",
    "        substrate_list, product_list = substrate_list, product_list\n",
    "\n",
    "    elif direction == \"REVERSIBLE\":\n",
    "        directed = False\n",
    "\n",
    "    else:\n",
    "        print(direction, \"why am I here\")\n",
    "\n",
    "    return substrate_list, product_list, directed\n",
    "\n",
    "\n",
    "def get_reaction_orientation_metacyc(substrate_list, product_list, ID):\n",
    "\n",
    "    from_metacyc = False\n",
    "    directed = False\n",
    "    \n",
    "    try:\n",
    "        m = metacyc_df.loc[ID]\n",
    "    except:\n",
    "        # no metacyc - \n",
    "        return substrate_list, product_list, directed, from_metacyc\n",
    " \n",
    "    direction = m[\"Reaction-Direction\"]\n",
    "\n",
    "    # manual checked\n",
    "    if ID in manually_checked_same:\n",
    "        from_metacyc = True\n",
    "        substrate_list, product_list, directed = orient_reaction_same(substrate_list, product_list, direction)\n",
    "\n",
    "    elif ID in manually_checked_reversed:\n",
    "        from_metacyc = True\n",
    "        substrate_list, product_list, directed = orient_reaction_reversed(substrate_list, product_list, direction)\n",
    "\n",
    "    elif ID in manually_checked_different:\n",
    "        pass \n",
    "    \n",
    "    # test here\n",
    "    else: \n",
    "        a = sum([i==j for i in m[\"RIGHT\"] for j in product_list])   > 0 # == len(product_list)\n",
    "        b = sum([i==j for i in m[\"LEFT\"]  for j in substrate_list]) > 0 # == len(substrate_list)\n",
    "\n",
    "        c = sum([i==j for i in m[\"RIGHT\"] for j in substrate_list]) > 0 # == len(substrate_list)\n",
    "        d = sum([i==j for i in m[\"LEFT\"]  for j in product_list])   > 0 # == len(product_list)\n",
    "\n",
    "        if (a and b):\n",
    "            from_metacyc = True\n",
    "            # same orientation\n",
    "            substrate_list, product_list, directed = orient_reaction_same(substrate_list, product_list, direction)\n",
    "\n",
    "        elif (c and d):\n",
    "            from_metacyc = True\n",
    "            # different orientation\n",
    "            substrate_list, product_list, directed = orient_reaction_reversed(substrate_list, product_list, direction)\n",
    "\n",
    "        else:\n",
    "            pass\n",
    "    \n",
    "    return substrate_list, product_list, directed, from_metacyc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "directions_from_metacyc = []\n",
    "glycans_to_add = []\n",
    "with open(product_relationship_file, 'w') as out_product:\n",
    "    with open(substrate_relationship_file, 'w') as out_substrate:\n",
    "        out_product.write(  '%s\\t%s\\t%s\\n'%('rxnID', 'cpdID', 'STOICHIOMETRY') )\n",
    "        out_substrate.write('%s\\t%s\\t%s\\n'%('rxnID', 'cpdID', 'STOICHIOMETRY') )\n",
    "        for i, row in df_reactions.iterrows():\n",
    "            ID = row['ID']\n",
    "            eqn = row['EQUATION']\n",
    "\n",
    "            try:\n",
    "                substrates, products = eqn.strip('\"').split(' <=> ')\n",
    "            except ValueError:\n",
    "                print('Failed at reaction %s, eqn is %s'%(row['ID'], eqn))\n",
    "                break\n",
    "\n",
    "            substrate_list = []\n",
    "            product_list = []\n",
    "            stochiometry_dict = {}\n",
    "\n",
    "            pattern = '^(.*?)\\s*([a-zA-Z]{1}[\\d]+)(.*?)$'\n",
    "            for targets, direction, compound_list in [\n",
    "                (substrates, 'substrate', substrate_list), \n",
    "                (products,   'product',   product_list)]:\n",
    "\n",
    "                for t in targets.split(' + '):\n",
    "                    stoichiometry_a, target, stoichiometry_b = re.match(pattern, t).groups()\n",
    "                    if target[0] == \"G\":\n",
    "                        try:\n",
    "                            target = df_gl_to_c.loc[target][\"compound\"]\n",
    "                        except KeyError:\n",
    "                            glycans_to_add.append(target)\n",
    "\n",
    "                    compound_list.append(target)\n",
    "\n",
    "                    if stoichiometry_a: \n",
    "                        stoichiometry = stoichiometry_a.strip(\"(\").strip(\")\")\n",
    "                    elif stoichiometry_b:\n",
    "                        stoichiometry = stoichiometry_b.strip(\"(\").strip(\")\")\n",
    "                    else:\n",
    "                        stoichiometry = 1\n",
    "\n",
    "                    stochiometry_dict[target] = stoichiometry\n",
    "\n",
    "            substrate_list, product_list, directed, from_metacyc = get_reaction_orientation_metacyc(substrate_list, product_list, ID)\n",
    "\n",
    "            for compound_list, file_ in ([substrate_list, out_substrate], \n",
    "                                         [product_list,   out_product]):\n",
    "                \n",
    "                for target in compound_list:\n",
    "                    stoichiometry = stochiometry_dict[target]\n",
    "                    s = '%s\\t%s\\t%s\\n'%(ID, target, stoichiometry)\n",
    "                    file_.write(s)\n",
    "            \n",
    "            if   (  directed and from_metacyc  ):\n",
    "                d = \"LEFTtoRIGHT\"\n",
    "            elif (  (not directed) and from_metacyc ):\n",
    "                d = \"REVERSIBLE\"\n",
    "            else:\n",
    "                d = \"None\"\n",
    "            \n",
    "            directions_from_metacyc.append(d)\n",
    "df_reactions [\"DIRECTION_FROM_METACYC\"] = directions_from_metacyc\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reactions.to_csv(reaction_entities_file, encoding=\"utf-8\", quoting=3, sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Compound vertices\n",
    "Includes all compounds, and any glycans referenced to in reactions that were not replaced by a compound. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_compounds = pd.read_csv(compounds_file_name, sep=\"\\t\", na_values=[\": NULL\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_glycans = pd.read_csv(glycans_file_name, sep=\"\\t\", na_values=[\": NULL\"])\n",
    "df_glycans.set_index(\"ENTRY\", drop=False, inplace=True)\n",
    "df_glycans = df_glycans.loc[list(set(glycans_to_add))]\n",
    "df_glycans.columns = df_compounds.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_compounds = df_compounds.append(df_glycans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create synonym list\n",
    "df_compounds[\"SYNONYMS\"] = [df_compounds[\"NAME\"][i].split(\"; \") if df_compounds[\"NAME\"][i] is not NaN\n",
    "                            else [df_compounds[\"ENTRY\"][i]] \n",
    "                            for i in range(df_compounds.shape[0])]\n",
    "pd.isnull(df_compounds[\"SYNONYMS\"]).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace name\n",
    "df_compounds[\"NAME\"] = df_compounds[\"SYNONYMS\"].apply(lambda x: \"%s\"%x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the pathway ids \n",
    "df_compounds[\"PATHWAY\"] = [re.findall(r'map[0-9]*', s) if s is not NaN \n",
    "                           else [] \n",
    "                           for s in df_compounds[\"PATHWAY\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# brite hierachy of compounds\n",
    "with open(compounds_brite_file_name, \"r\") as handle:\n",
    "    j = json.load(handle)\n",
    "\n",
    "def tree(k):\n",
    "    parent = re.sub('\\[.*\\]', '', k[\"name\"]).strip()\n",
    "    children = k[\"children\"]\n",
    "    for d in children:\n",
    "        child = re.sub('\\[.*\\]', '', d[\"name\"]).strip()\n",
    "        if not \"children\" in d.keys():\n",
    "            child = child.split(\" \")[0]\n",
    "            \n",
    "        parents[child].append(parent)\n",
    "        if \"children\" in d.keys():\n",
    "            tree(d)\n",
    "parents = defaultdict(list)\n",
    "tree(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Peptides'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dumb peptides linking to peptides\n",
    "parents[\"Peptides\"].pop(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ancestors(c):\n",
    "    \n",
    "    def recursive_ancestors(c, ancestors):\n",
    "        if c in parents:\n",
    "            for p in parents[c]:\n",
    "                ancestors.append(p)\n",
    "                ancestors = recursive_ancestors(p, ancestors)\n",
    "        return ancestors\n",
    "    \n",
    "    ancestors = recursive_ancestors(c, [])\n",
    "    return ancestors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_compounds[\"BRITE_HIERARCHY\"] = df_compounds[\"ENTRY\"].apply(get_ancestors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all lists to strings\n",
    "df_compounds[\"PATHWAY\"] = df_compounds[\"PATHWAY\"].apply(list_to_string)\n",
    "df_compounds[\"SYNONYMS\"] = df_compounds[\"SYNONYMS\"].apply(list_to_string)\n",
    "df_compounds[\"BRITE_HIERARCHY\"] = df_compounds[\"BRITE_HIERARCHY\"].apply(list_to_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_compounds = df_compounds[[\"ENTRY\", \"NAME\", \"SYNONYMS\", \"FORMULA\", \"PATHWAY\", \"BRITE_HIERARCHY\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_compounds.columns = ['ID', \n",
    "                        'NAME', \n",
    "                        'SYNONYMS', \n",
    "                        'FORMULA', \n",
    "                        'PATHWAY', \n",
    "                        'BRITE_HIERARCHY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_compounds.to_csv(compound_entities_file, encoding=\"utf-8\", quoting=3, sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
